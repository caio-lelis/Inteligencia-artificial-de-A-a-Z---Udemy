{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Machine Learning e Data Science com Python de A à Z (Classificacão) - IA Expert Academy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação\n",
    "\n",
    "#!pip -q install plotly\n",
    "#!pip -q install yellowbrick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados de crédito\n",
    "\n",
    "- Fonte (adaptado): https://www.kaggle.com/laotse/credit-risk-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv('credit-data.csv')\n",
    "\n",
    "df_credit.head() # Exibindo as primeiras linhas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos analisar os atributos da base de dados de crédito e definir o tipo de variável de cada um deles.\n",
    "\n",
    "- **Atributos:**\n",
    "    - **clientid** - Id do cliente -> Variável categórica nominal\n",
    "    - **Income** - Renda -> Variável numérica contínua\n",
    "    - **Age** - Idade -> Variável numérica contínua\n",
    "    - **Loan** - Dívida -> Variável numérica contínua\n",
    "    - **c#default** - Pagou/ñ pagou emprestimo -> Variável numérica discreta -> **Variável target**\n",
    "    \n",
    "obs. default = 0 -> Pagou\n",
    "\n",
    "obs. default = 1 -> Não pagou\n",
    "\n",
    "#### Objetivo:\n",
    "\n",
    "- Nosso objetivo é criar um modelo de Machine Learning para prever se um cliente irá pagar ou não o empréstimo de acordo com as variáveis presentes acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.tail() # Exibindo as últimas linhas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.describe() # Exibindo informações estatísticas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit[df_credit['income'] >= 69995.685578] # Exibindo os registros da pessoa com maior renda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo a quantidade de registros para cada classe da variável default\n",
    "np.unique(df_credit['default'], return_counts=True) \n",
    "\n",
    "#Resultado :\n",
    "\n",
    "# 0: 1717 registros -> pagantes\n",
    "# 1: 283 registros -> não pagantes\n",
    "# 1° análise : A base de dados está desbalanceada, pois a quantidade de pagantes é muito maior que a quantidade de não pagantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='default', data=df_credit);\n",
    "plt.title('Quantidade de pagantes e não pagantes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['age'], bins=20, color='blue', edgecolor='black');\n",
    "plt.title('Distribuição da idade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['income'], color='blue', edgecolor='black');\n",
    "plt.title('Distribuição da renda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['loan'], color='blue', edgecolor='black');\n",
    "plt.title('Distribuição do empréstimo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.scatter_matrix(df_credit, dimensions=['age', 'income' ,'loan'], color='default')\n",
    "grafico.show()\n",
    "#scatter => gráfico de dispersão interessante para observar valores que estão fora do quadrante de normalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise pelo gráfico de dispersão, conseguimos encontrar alguns padrões de usuários não pagantes e também 3 anomalias na coluna 'Age' com idades negativas que iremos corrigir agora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos dos valores inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.loc[df_credit['age'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Técnicas para tratar valores negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar a coluna inteira (não recomendado quando se tem poucos dados inconsistentes)\n",
    "df_credit2 = df_credit.drop('age' , axis=1)\n",
    "df_credit2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar somente os registros com valores inconsistentes\n",
    "indices = df_credit[df_credit['age'] < 0].index\n",
    "df_credit3 = df_credit.drop(indices)\n",
    "df_credit3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se ainda existem valores de idade menores que 0\n",
    "df_credit3.loc[df_credit3['age'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher os valores inconsistentes manualmente (Recomendado quando se tem poucos dados inconsistentes)\n",
    "\n",
    "# Aqui iremos preencher o valor de idade negativo com a média das idades\n",
    "\n",
    "df_credit['age'].mean()\n",
    "\n",
    "# Nota-se que aqui a um problema, pois essa média calculada tem como unidade de medida os valores inconsistentes, \n",
    "#ou seja, a média está incorreta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achando a média real\n",
    "\n",
    "df_credit['age'][df_credit['age'] > 0].mean() # Média é igual a 40.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo os valores inconsistentes com a média correta\n",
    "\n",
    "df_credit.loc[df_credit['age'] < 0, 'age'] = 40.92\n",
    "\n",
    "# Validando se ainda existem valores de idade menores que 0\n",
    "\n",
    "df_credit.loc[df_credit['age'] < 0]\n",
    "\n",
    "df_credit.head(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.isnull().sum() # Verificando se existem valores nulos\n",
    "\n",
    "df_credit.loc[pd.isnull(df_credit['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher os registros nulos com a média\n",
    "\n",
    "df_credit['age'].fillna(df_credit['age'].mean() , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se os Valores Nulos foram registrados com a Média\n",
    "\n",
    "df_credit.loc[(df_credit['clientid']== 29) | (df_credit['clientid']== 30) | (df_credit['clientid']== 31)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão da base de dados em treino e teste (Previsores e Classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente chama-se a base de dados de previsores de X e a base de dados de classe de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iremos pegar todos os registros das colunas \"income\" , \"age\" e \"loan\"\n",
    "x_credit = df_credit.iloc[ : , 1:4].values\n",
    "x_credit # Exibindo os valores, nota-se que foi convertido os valores de dataframe do pandas para array do numpy\n",
    "         # Isto foi feito com o \".values\" para que converta pois os modelos de ML só conseguem trabalhar com arrays do numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pegando os valores da coluna \"default\" que é a nossa variável alvo\n",
    "\n",
    "y_credit = df_credit.iloc[ : , 4].values\n",
    "y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento dos Valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.61559251e+04, 5.90170151e+01, 8.10653213e+03],\n",
       "       [3.44151540e+04, 4.81171531e+01, 6.56474502e+03],\n",
       "       [5.73171701e+04, 6.31080495e+01, 8.02095330e+03],\n",
       "       ...,\n",
       "       [4.43114493e+04, 2.80171669e+01, 5.52278669e+03],\n",
       "       [4.37560566e+04, 6.39717958e+01, 1.62272260e+03],\n",
       "       [6.94365796e+04, 5.61526170e+01, 7.37883360e+03]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(20014.4894700497),\n",
       " np.float64(18.055188510566897),\n",
       " np.float64(1.37762959325451))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit[:,0].min() , x_credit[:,1].min() , x_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(69995.6855783239),\n",
       " np.float64(63.971795841120205),\n",
       " np.float64(13766.0512393337))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit[: , 0].max() , x_credit[: , 1].max() , x_credit[: , 2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os valores vimos que algumas variáveis são muito maiores que outras e vice-versa , isso pode fazer com que na hora que iremos aplicar algoritmos de Machine learning encima desses dados ele possa se enviesar e achar que variáveis com valores maiores são mais importantes do que variáveis com valores menores, para isso vamos aplicar a técnica de escalonamento de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Importando a biblioteca para normalização dos dados\n",
    "\n",
    "scaler_credit = StandardScaler()\n",
    "x_credit = scaler_credit.fit_transform(x_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-1.7676158019964077),\n",
       " np.float64(-1.7264145408889917),\n",
       " np.float64(-1.4592791099462408))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit[:,0].min() , x_credit[:,1].min() , x_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.7220222385319197),\n",
       " np.float64(1.7393673928651967),\n",
       " np.float64(3.0616609141708273))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_credit[: , 0].max() , x_credit[: , 1].max() , x_credit[: , 2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que agora os dados estão mais escalonados e os algoritmso de Machine Learning irão se comportar melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Dados do Censo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
