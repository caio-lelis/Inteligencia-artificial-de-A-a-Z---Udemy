{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Machine Learning e Data Science com Python de A à Z (Classificacão) - IA Expert Academy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação\n",
    "\n",
    "#!pip -q install plotly\n",
    "#!pip -q install yellowbrick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados de crédito\n",
    "\n",
    "- Fonte (adaptado): https://www.kaggle.com/laotse/credit-risk-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv('credit-data.csv')\n",
    "\n",
    "df_credit.head() # Exibindo as primeiras linhas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos analisar os atributos da base de dados de crédito e definir o tipo de variável de cada um deles.\n",
    "\n",
    "- **Atributos:**\n",
    "    - **clientid** - Id do cliente -> Variável categórica nominal\n",
    "    - **Income** - Renda -> Variável numérica contínua\n",
    "    - **Age** - Idade -> Variável numérica contínua\n",
    "    - **Loan** - Dívida -> Variável numérica contínua\n",
    "    - **c#default** - Pagou/ñ pagou emprestimo -> Variável numérica discreta -> **Variável target**\n",
    "    \n",
    "obs. default = 0 -> Pagou\n",
    "\n",
    "obs. default = 1 -> Não pagou\n",
    "\n",
    "#### Objetivo:\n",
    "\n",
    "- Nosso objetivo é criar um modelo de Machine Learning para prever se um cliente irá pagar ou não o empréstimo de acordo com as variáveis presentes acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.tail() # Exibindo as últimas linhas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.describe() # Exibindo informações estatísticas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit[df_credit['income'] >= 69995.685578] # Exibindo os registros da pessoa com maior renda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo a quantidade de registros para cada classe da variável default\n",
    "np.unique(df_credit['default'], return_counts=True) \n",
    "\n",
    "#Resultado :\n",
    "\n",
    "# 0: 1717 registros -> pagantes\n",
    "# 1: 283 registros -> não pagantes\n",
    "# 1° análise : A base de dados está desbalanceada, pois a quantidade de pagantes é muito maior que a quantidade de não pagantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='default', data=df_credit);\n",
    "plt.title('Quantidade de pagantes e não pagantes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['age'], bins=20, color='blue', edgecolor='black');\n",
    "plt.title('Distribuição da idade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['income'], color='blue', edgecolor='black');\n",
    "plt.title('Distribuição da renda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_credit['loan'], color='blue', edgecolor='black');\n",
    "plt.title('Distribuição do empréstimo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.scatter_matrix(df_credit, dimensions=['age', 'income' ,'loan'], color='default')\n",
    "grafico.show()\n",
    "#scatter => gráfico de dispersão interessante para observar valores que estão fora do quadrante de normalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise pelo gráfico de dispersão, conseguimos encontrar alguns padrões de usuários não pagantes e também 3 anomalias na coluna 'Age' com idades negativas que iremos corrigir agora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos dos valores inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.loc[df_credit['age'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Técnicas para tratar valores negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar a coluna inteira (não recomendado quando se tem poucos dados inconsistentes)\n",
    "df_credit2 = df_credit.drop('age' , axis=1)\n",
    "df_credit2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar somente os registros com valores inconsistentes\n",
    "indices = df_credit[df_credit['age'] < 0].index\n",
    "df_credit3 = df_credit.drop(indices)\n",
    "df_credit3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se ainda existem valores de idade menores que 0\n",
    "df_credit3.loc[df_credit3['age'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher os valores inconsistentes manualmente (Recomendado quando se tem poucos dados inconsistentes)\n",
    "\n",
    "# Aqui iremos preencher o valor de idade negativo com a média das idades\n",
    "\n",
    "df_credit['age'].mean()\n",
    "\n",
    "# Nota-se que aqui a um problema, pois essa média calculada tem como unidade de medida os valores inconsistentes, \n",
    "#ou seja, a média está incorreta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achando a média real\n",
    "\n",
    "df_credit['age'][df_credit['age'] > 0].mean() # Média é igual a 40.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo os valores inconsistentes com a média correta\n",
    "\n",
    "df_credit.loc[df_credit['age'] < 0, 'age'] = 40.92\n",
    "\n",
    "# Validando se ainda existem valores de idade menores que 0\n",
    "\n",
    "df_credit.loc[df_credit['age'] < 0]\n",
    "\n",
    "df_credit.head(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.isnull().sum() # Verificando se existem valores nulos\n",
    "\n",
    "df_credit.loc[pd.isnull(df_credit['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher os registros nulos com a média\n",
    "\n",
    "df_credit['age'].fillna(df_credit['age'].mean() , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando se os Valores Nulos foram registrados com a Média\n",
    "\n",
    "df_credit.loc[(df_credit['clientid']== 29) | (df_credit['clientid']== 30) | (df_credit['clientid']== 31)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão da base de dados em treino e teste (Previsores e Classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente chama-se a base de dados de previsores de X e a base de dados de classe de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iremos pegar todos os registros das colunas \"income\" , \"age\" e \"loan\"\n",
    "x_credit = df_credit.iloc[ : , 1:4].values\n",
    "x_credit # Exibindo os valores, nota-se que foi convertido os valores de dataframe do pandas para array do numpy\n",
    "         # Isto foi feito com o \".values\" para que converta pois os modelos de ML só conseguem trabalhar com arrays do numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando os valores da coluna \"default\" que é a nossa variável alvo\n",
    "\n",
    "y_credit = df_credit.iloc[ : , 4].values\n",
    "y_credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento dos Valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit[:,0].min() , x_credit[:,1].min() , x_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit[: , 0].max() , x_credit[: , 1].max() , x_credit[: , 2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os valores vimos que algumas variáveis são muito maiores que outras e vice-versa , isso pode fazer com que na hora que iremos aplicar algoritmos de Machine learning encima desses dados ele possa se enviesar e achar que variáveis com valores maiores são mais importantes do que variáveis com valores menores, para isso vamos aplicar a técnica de escalonamento de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # Importando a biblioteca para normalização dos dados\n",
    "\n",
    "scaler_credit = StandardScaler()\n",
    "x_credit = scaler_credit.fit_transform(x_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit[:,0].min() , x_credit[:,1].min() , x_credit[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_credit[: , 0].max() , x_credit[: , 1].max() , x_credit[: , 2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que agora os dados estão mais escalonados e os algoritmso de Machine Learning irão se comportar melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Dados do Censo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census = pd.read_csv('census.csv')\n",
    "df_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploração de Dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos atributos da base de dados do censo e definição do tipo de variável de cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- **Atributos:**\n",
    "    - **age** - Idade -> Variável numérica discreta\n",
    "    - **workclass** - Classe trabalhadora -> Variável categórica nominal\n",
    "    - **final-weight** - Pontuação -> Variável numérica contínua \n",
    "    - **education** - Educação -> variavel categórica ordinal\n",
    "    - **education-num** - Número de anos de educação -> Variável numérica discreta\n",
    "    - **marital-status** - Estado civil -> Variável categórica nominal\n",
    "    - **occupation** - Ocupação -> Variável categórica nominal\n",
    "    - **relationship** - Relacionamento -> Variável categórica nominal\n",
    "    - **race** - Raça -> Variável categórica nominal\n",
    "    - **sex** - Sexo -> Variável categórica nominal\n",
    "    - **capital-gain** - Ganho de capital -> Variável numérica contínua\n",
    "    - **capital-loos** - Perda de capital -> Variável numérica contínua\n",
    "    - **hour-per-week** - Horas de trabalho por semana -> Variável numérica contínua\n",
    "    - **native-country** - País de origem -> Variável categórica nominal\n",
    "    - **income** - Renda -> Variável categórica ordinal -> **Variável target**\n",
    "\n",
    "#### Objetivo:\n",
    "\n",
    "- Nosso objetivo é criar um modelo de Machine Learning para prever se a renda de uma pessoa é maior ou menor que 50k por ano de acordo com as variáveis presentes acima.\n",
    "\n",
    "#### Saídas possíveis para o Income:\n",
    "\n",
    "- **income <= 50k**\n",
    "- **income > 50k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizando estatísticas\n",
    "\n",
    "df_census.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando Valores Nulos\n",
    "df_census.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_census['income'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos que 24720 pessoas ganham menos que 50k e 7841 pessoas ganham mais que 50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df_census['income']);\n",
    "\n",
    "# Através do gráfico podemos ver que a base de dados está desbalanceada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df_census['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df_census['education-num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x=df_census['hour-per-week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.treemap(df_census,path=['workclass' , 'age'])\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.treemap(df_census,path=['occupation' , 'relationship' , 'age'])\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.parallel_categories(df_census, dimensions=['occupation' , 'relationship'])\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.parallel_categories(df_census, dimensions=[ 'workclass','occupation' , 'relationship', 'income'])\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico = px.parallel_categories(df_census, dimensions=[ 'education','income'])\n",
    "grafico.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão entre previsores e classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census = df_census.iloc[: , 0:14].values\n",
    "y_census = df_census.iloc[: , 14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validando colunas\n",
    "x_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de atributos categóricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendendo o LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder_teste = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[: ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = label_encoder_teste.fit_transform(x_census[: ,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se perceber que ao usar labelencoder ele transforma os valores possíveis das variáveis categóricas em valores numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando LabelEncoder em todas as variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_workclass = LabelEncoder()\n",
    "label_encoder_education = LabelEncoder()\n",
    "label_encoder_marital = LabelEncoder()\n",
    "label_encoder_occupation = LabelEncoder()\n",
    "label_encoder_relationship = LabelEncoder()\n",
    "label_encoder_race = LabelEncoder()\n",
    "label_encoder_sex = LabelEncoder()\n",
    "label_encoder_country = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[: ,1] = label_encoder_workclass.fit_transform(x_census[: ,1])\n",
    "x_census[: ,3] = label_encoder_education.fit_transform(x_census[: ,3])\n",
    "x_census[: ,5] = label_encoder_marital.fit_transform(x_census[: ,5])\n",
    "x_census[: ,6] = label_encoder_occupation.fit_transform(x_census[: ,6])\n",
    "x_census[: ,7] = label_encoder_relationship.fit_transform(x_census[: ,7])\n",
    "x_census[:, 8] = label_encoder_race.fit_transform(x_census[:, 8])\n",
    "x_census[:, 9] = label_encoder_sex.fit_transform(x_census[:, 9])\n",
    "x_census[:, 13] = label_encoder_country.fit_transform(x_census[:, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, agora que transformamos todas as variáveis categóricas em numéricas, vamos aplicar o OneHotEncoder para que o algoritmo de Machine Learning não entenda que uma variável é maior que a outra por conta do valor numérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o OneHotEncoder transforma as variáveis categóricas em variáveis binárias. criando uma coluna para cada valor possível da variável categórica. a coluna que tiver o valor 1 é a que representa o valor da variável categórica, o restante das colunas terão o valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder_census = ColumnTransformer(transformers=[('OneHot', OneHotEncoder(), \n",
    "                                                       [1 , 3 , 5 , 6 , 7 , 8 , 9 , 13 ])],\n",
    "                                                       remainder='passthrough')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census = onehotencoder_census.fit_transform(x_census).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pode-se perceber que agora temos 108 colunas, isso acontece porque o OneHotEncoder criou uma coluna para cada valor possível das variáveis categóricas. Logo, todo objeto do nossso dataset agora é representado por 108 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalonamento dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_census = StandardScaler()\n",
    "x_census = scaler_census.fit_transform(x_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_census[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
